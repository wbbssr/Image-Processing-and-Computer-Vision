{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Step 1: Compute the texture descriptions for the training images.\n",
    "\n",
    "For each training image, calculate a vector of GLCM features.  Which GLCM features and the set of displacements you choose to you use are up to you (note that displacements for `skimage.feature.graycomatrix()` need to be specified by distances and angles in radians rather than change in x and y directions).  Experiment to obtain the best possible classification rate.  Use conservative choices to begin with until everything is working, then come back and experiemnt.  As described in the Topic 10 lecture notes, use `skimage.feature.graycomatrix()` and `skimage.feature.graycoprops()` to calculate GLCM features.  You'll probably want to use `normed=True` with `graycomatrix`.  Your GLCM features should be stored as a 120-row array by m-element array, (m will depend on how many different features and displacements you used and whether or not you combine values for different displacements or not, e.g., by taking their mean).  \n",
    "\n",
    "_Hint: Pay close attention to the format of the return values of  `graycomatrix()` and `graycoprops()`._\n",
    "\n",
    "Also, for each training image, calculate the rotationally invariant LBP features using `skiamge.feature.local_binary_pattern()`.  You can experiment with parameters `P` and `R` to get a good classification rate, but probably `P=8` and `R=1` are good enough.   For the `method` parameter, use `'uniform'` which gives you the LBP flavour we talked about in class.   Remember that `skiamge.feature.local_binary_pattern()` returns an \"LBP Image\", which is an image in which the pixel value is between 0 and 9, and corresponds to one of the ten possible pattern labels.  It's up to you to turn the \"LBP Image\" into a 10-bin histogram, which serves as the feature vector for that image (you can use `numpy.histogram` for this but again remember to specify `bins` and `range` parameters, and that it returns two things, and you only need the first one). \n",
    "\n",
    "Addionally, calculate the LBP variance feature again using `skimage.feature.local_binary_pattern()` but use `method='var'` instead.  This is the VAR feature we saw in class.  Use the same P and R as before.  Build a 16-bin histogram of the resulting 'LBP-VAR' image; use `range=(0,7000)` with `numpy.hisotgram()` (this is not quite \"correct\", but it's good enough).  Concatenate these with the rotationally invariant LBP features so that you have a 26-element feature vector for each training image.   These should be stored as a 120-row, 26-column array.\n",
    "\n",
    "You can do this all in one loop which builds both feature arrays.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wbb/anaconda3/envs/cmpt819/lib/python3.7/site-packages/numpy/lib/histograms.py:746: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  keep = (tmp_a >= first_edge)\n",
      "/Users/wbb/anaconda3/envs/cmpt819/lib/python3.7/site-packages/numpy/lib/histograms.py:747: RuntimeWarning: invalid value encountered in less_equal\n",
      "  keep &= (tmp_a <= last_edge)\n"
     ]
    }
   ],
   "source": [
    "# Write your code here.\n",
    "import numpy as np\n",
    "import skimage.segmentation as seg\n",
    "import skimage.morphology as morph\n",
    "import os as os\n",
    "import skimage.io as io\n",
    "import skimage.feature as feat\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage\n",
    "% matplotlib inline\n",
    "\n",
    "train_path = os.path.join('.', 'brodatztraining')\n",
    "\n",
    "train_ftrs = np.empty(shape=(0, 64))\n",
    "train_lbp = np.empty(shape=(0,26))\n",
    "\n",
    "for root, dirs, files in os.walk(train_path):\n",
    "    for filename in files:\n",
    "        # ignore files that are not PNG files.\n",
    "        if filename[-4:] != '.png':\n",
    "            continue\n",
    "        \n",
    "        # concatenate variable root with filename to get the path to an input file.\n",
    "        fname = os.path.join(root, filename)\n",
    "        I = io.imread(fname)\n",
    "        P = feat.greycomatrix(I, [1, 2, 3, 4], [0, np.pi/4, np.pi/2, 3*np.pi/4], normed=True)\n",
    "        energy = feat.greycoprops(P, 'energy')\n",
    "        energy = np.reshape(energy, (1, np.product(energy.shape)))\n",
    "        contrast = feat.greycoprops(P, 'contrast')\n",
    "        contrast = np.reshape(contrast, (1, np.product(contrast.shape)))\n",
    "        correlation = feat.greycoprops(P, 'correlation')\n",
    "        correlation = np.reshape(correlation, (1, np.product(correlation.shape)))\n",
    "        homogeneity = feat.greycoprops(P, 'homogeneity')\n",
    "        homogeneity = np.reshape(homogeneity, (1, np.product(homogeneity.shape)))\n",
    "        conca = np.concatenate((energy, contrast, correlation, homogeneity), axis=1)\n",
    "        train_ftrs = np.concatenate((train_ftrs, conca), axis=0)\n",
    "        \n",
    "        uniform = feat.local_binary_pattern(I, P=8, R=1, method='uniform')\n",
    "        hist_uni, bin_edges_uni = np.histogram(uniform, bins=10, range=(0,9))\n",
    "        hist_uni = np.reshape(hist_uni, (1, -1))\n",
    "        var = feat.local_binary_pattern(I, P=8, R=1, method='var')\n",
    "        hist_var, bin_edges_var = np.histogram(var, bins=16, range=(0,7000))\n",
    "        hist_var = np.reshape(hist_var, (1, -1))\n",
    "        train_lbp = np.concatenate((train_lbp, np.concatenate((hist_uni, hist_var), axis=1)), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Compute Test Image Features\n",
    "\n",
    "Compute the exact same features as you did in step 1 for each of the test images.  Store them in the same way (these arrays will just have more rows, specifically 320 rows, one for each testing sample). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wbb/anaconda3/envs/cmpt819/lib/python3.7/site-packages/numpy/lib/histograms.py:746: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  keep = (tmp_a >= first_edge)\n",
      "/Users/wbb/anaconda3/envs/cmpt819/lib/python3.7/site-packages/numpy/lib/histograms.py:747: RuntimeWarning: invalid value encountered in less_equal\n",
      "  keep &= (tmp_a <= last_edge)\n"
     ]
    }
   ],
   "source": [
    "# Write your code here.  \n",
    "test_path = os.path.join('.', 'brodatztesting')\n",
    "\n",
    "test_ftrs = np.empty(shape=(0, 64))\n",
    "test_lbp = np.empty(shape=(0,26))\n",
    "for root, dirs, files in os.walk(test_path):\n",
    "    for filename in files:\n",
    "        # ignore files that are not PNG files.\n",
    "        if filename[-4:] != '.png':\n",
    "            continue\n",
    "        \n",
    "        # concatenate variable root with filename to get the path to an input file.\n",
    "        fname = os.path.join(root, filename)\n",
    "        I = io.imread(fname)\n",
    "        P = feat.greycomatrix(I, [1, 2, 3, 4], [0, np.pi/4, np.pi/2, 3*np.pi/4], normed=False)\n",
    "        P_flt = P.astype(float)\n",
    "        for i in range(P_flt.shape[2]):\n",
    "            for j in range(P_flt.shape[3]):\n",
    "                P_flt[0,0,i,j] = 0\n",
    "                P_flt[0,0,i,j] = np.max(P_flt[:,:,i,j]) % 10.0\n",
    "                P_flt[:,:,i,j] = P_flt[:,:,i,j] / np.sum(P_flt[:,:,i,j])\n",
    "        energy = feat.greycoprops(P_flt, 'energy')\n",
    "        energy = np.reshape(energy, (1, np.product(energy.shape)))\n",
    "        contrast = feat.greycoprops(P_flt, 'contrast')\n",
    "        contrast = np.reshape(contrast, (1, np.product(contrast.shape)))\n",
    "        correlation = feat.greycoprops(P_flt, 'correlation')\n",
    "        correlation = np.reshape(correlation, (1, np.product(correlation.shape)))\n",
    "        homogeneity = feat.greycoprops(P_flt, 'homogeneity')\n",
    "        homogeneity = np.reshape(homogeneity, (1, np.product(homogeneity.shape)))\n",
    "        conca = np.concatenate((energy, contrast, correlation, homogeneity), axis=1)\n",
    "        test_ftrs = np.concatenate((test_ftrs, conca), axis=0)\n",
    "        \n",
    "        uniform = feat.local_binary_pattern(I, P=8, R=1, method='uniform')\n",
    "        hist_uni, bin_edges_uni = np.histogram(uniform, bins=10, range=(0,9))\n",
    "        hist_uni = np.reshape(hist_uni, (1, -1))\n",
    "        var = feat.local_binary_pattern(I, P=8, R=1, method='var')\n",
    "        hist_var, bin_edges_var = np.histogram(var, bins=16, range=(0,7000))\n",
    "        hist_var = np.reshape(hist_var, (1, -1))\n",
    "        test_lbp = np.concatenate((test_lbp, np.concatenate((hist_uni, hist_var), axis=1)), axis=0)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Generate Label Arrays for the Training and Testing Data\n",
    "\n",
    "Use labels 1 for the first class, label 2 for the second class, etc.   This should be easy to do since the filenames are ordered in blocks of 15 or 40 images of each class for training and testing respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code for step 3 here. \n",
    "\n",
    "train_y = []\n",
    "test_y = []\n",
    "image_filename = []\n",
    "count_train_img = 0\n",
    "count_test_img = 0\n",
    "\n",
    "for root, dirs, files in os.walk(train_path):\n",
    "    for filename in files:\n",
    "        # ignore files that are not PNG files.\n",
    "        if filename[-4:] != '.png':\n",
    "            continue\n",
    "        \n",
    "        # concatenate variable root with filename to get the path to an input file.\n",
    "        fname = os.path.join(root, filename)\n",
    "        count_train_img = count_train_img + 1\n",
    "        if (count_train_img <= 15):\n",
    "            train_y.append(1)\n",
    "        elif (count_train_img <= 30):\n",
    "            train_y.append(2)\n",
    "        elif (count_train_img <= 45):\n",
    "            train_y.append(3)\n",
    "        elif (count_train_img <= 60):\n",
    "            train_y.append(4)\n",
    "        elif (count_train_img <= 75):\n",
    "            train_y.append(5)\n",
    "        elif (count_train_img <= 90):\n",
    "            train_y.append(6)\n",
    "        elif (count_train_img <= 105):\n",
    "            train_y.append(7)\n",
    "        else:\n",
    "            train_y.append(8)\n",
    "\n",
    "for root, dirs, files in os.walk(test_path):\n",
    "    for filename in files:\n",
    "        # ignore files that are not PNG files.\n",
    "        if filename[-4:] != '.png':\n",
    "            continue\n",
    "        \n",
    "        # concatenate variable root with filename to get the path to an input file.\n",
    "        fname = os.path.join(root, filename)\n",
    "        image_filename.append(filename)\n",
    "        count_test_img = count_test_img + 1\n",
    "        if (count_test_img <= 40):\n",
    "            test_y.append(1)\n",
    "        elif (count_test_img <= 80):\n",
    "            test_y.append(2)\n",
    "        elif (count_test_img <= 120):\n",
    "            test_y.append(3)\n",
    "        elif (count_test_img <= 160):\n",
    "            test_y.append(4)\n",
    "        elif (count_test_img <= 200):\n",
    "            test_y.append(5)\n",
    "        elif (count_test_img <= 240):\n",
    "            test_y.append(6)\n",
    "        elif (count_test_img <= 280):\n",
    "            test_y.append(7)\n",
    "        else:\n",
    "            test_y.append(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4:  Train an KNN classifier.  \n",
    "\n",
    "Train an KNN  classifier using your GLCM features.  Train another one using your LBP features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.neighbors as knn\n",
    "\n",
    "# Write your code here. This should be quite short.\n",
    "ngh_ftrs = knn.KNeighborsClassifier(n_neighbors=1)\n",
    "ngh_ftrs.fit(train_ftrs, train_y)\n",
    "\n",
    "ngh_lbp = knn.KNeighborsClassifier(n_neighbors=1)\n",
    "ngh_lbp.fit(train_lbp, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4:  Predict the classes of the test images\n",
    "\n",
    "Predict the classes of the test images using both classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here.  Again this should be quite short.\n",
    "test_y_ftrs_pred = ngh_ftrs.predict(test_ftrs)\n",
    "test_y_lbp_pred = ngh_lbp.predict(test_lbp)\n",
    "test_y = np.array(test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6:  Display Results\n",
    "\n",
    "Display results as in the final step of Question 1.  For each classifier display the image filenames that were incorrectly classified, the confisuion matrix, and the classification rate.  \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "###############GLCM classifier####################\n",
      "##################################################\n",
      "The classification rate was: 0.812500000000\n",
      "--------------------------------------------------\n",
      "The confusion matrix was: \n",
      "[[27  3 10  0  0  0  0  0]\n",
      " [ 0 33  0  0  0  0  0  7]\n",
      " [ 0  0 17  0  0  0 17  6]\n",
      " [ 0  0  0 31  0  0  1  0]\n",
      " [ 0  0  0  0 40  0  0  0]\n",
      " [ 0  0  0  0  0 40  0  0]\n",
      " [ 0  0  0  0  0  0 32  8]\n",
      " [ 0  0  0  0  0  0  0 40]]\n",
      "--------------------------------------------------\n",
      "Incorrectly classified images was: \n",
      "patch-116291.png\n",
      "patch-120541.png\n",
      "patch-124729.png\n",
      "patch-131612.png\n",
      "patch-131973.png\n",
      "patch-136304.png\n",
      "patch-140252.png\n",
      "patch-140870.png\n",
      "patch-144596.png\n",
      "patch-154835.png\n",
      "patch-158692.png\n",
      "patch-159392.png\n",
      "patch-163446.png\n",
      "patch-204094.png\n",
      "patch-210674.png\n",
      "patch-217835.png\n",
      "patch-231503.png\n",
      "patch-231574.png\n",
      "patch-232913.png\n",
      "patch-248638.png\n",
      "patch-305067.png\n",
      "patch-305313.png\n",
      "patch-305978.png\n",
      "patch-306264.png\n",
      "patch-306753.png\n",
      "patch-311821.png\n",
      "patch-317973.png\n",
      "patch-328908.png\n",
      "patch-330503.png\n",
      "patch-331575.png\n",
      "patch-332422.png\n",
      "patch-332896.png\n",
      "patch-333434.png\n",
      "patch-336303.png\n",
      "patch-336860.png\n",
      "patch-336879.png\n",
      "patch-337484.png\n",
      "patch-338483.png\n",
      "patch-345931.png\n",
      "patch-347840.png\n",
      "patch-349196.png\n",
      "patch-352523.png\n",
      "patch-354594.png\n",
      "patch-412510.png\n",
      "patch-416163.png\n",
      "patch-417064.png\n",
      "patch-434225.png\n",
      "patch-449686.png\n",
      "patch-449855.png\n",
      "patch-453537.png\n",
      "patch-455370.png\n",
      "patch-464150.png\n",
      "patch-708324.png\n",
      "patch-717001.png\n",
      "patch-726856.png\n",
      "patch-738682.png\n",
      "patch-739199.png\n",
      "patch-759385.png\n",
      "patch-760605.png\n",
      "patch-764237.png\n",
      "##################################################\n",
      "################LBP classifier####################\n",
      "##################################################\n",
      "The classification rate was: 0.987500000000\n",
      "--------------------------------------------------\n",
      "The confusion matrix was: \n",
      "[[38  0  2  0  0  0  0  0]\n",
      " [ 0 38  0  0  0  0  0  2]\n",
      " [ 0  0 40  0  0  0  0  0]\n",
      " [ 0  0  0 40  0  0  0  0]\n",
      " [ 0  0  0  0 40  0  0  0]\n",
      " [ 0  0  0  0  0 40  0  0]\n",
      " [ 0  0  0  0  0  0 40  0]\n",
      " [ 0  0  0  0  0  0  0 40]]\n",
      "--------------------------------------------------\n",
      "Incorrectly classified images was: \n",
      "patch-136304.png\n",
      "patch-142400.png\n",
      "patch-210674.png\n",
      "patch-248638.png\n"
     ]
    }
   ],
   "source": [
    "# Write your code here.\n",
    "print(\"##################################################\")\n",
    "print(\"###############GLCM classifier####################\")\n",
    "print(\"##################################################\")\n",
    "err_ftrs_pred = test_y - test_y_ftrs_pred\n",
    "err_ftrs_pred_abs = abs(err_ftrs_pred)\n",
    "ftrs_cls_rate = sum(np.logical_not(err_ftrs_pred_abs)) * 1.0 / test_y.shape[0]\n",
    "print(\"The classification rate was: %.12f\" % ftrs_cls_rate)\n",
    "print(\"--------------------------------------------------\")\n",
    "ftrs_conf_mx = np.zeros((8,8),dtype=int)\n",
    "ftrs_err_idx = np.where(err_ftrs_pred)\n",
    "ftrs_err_idx = ftrs_err_idx[0]\n",
    "for i in ftrs_err_idx:\n",
    "    if (i < 40):\n",
    "        ftrs_conf_mx[0, (0 - err_ftrs_pred[i])] = ftrs_conf_mx[0, (0 - err_ftrs_pred[i])] + 1\n",
    "    elif (i < 80):\n",
    "        ftrs_conf_mx[1, (0 - err_ftrs_pred[i])] = ftrs_conf_mx[1, (0 - err_ftrs_pred[i])] + 1\n",
    "    elif (i < 120):\n",
    "        ftrs_conf_mx[2, (0 - err_ftrs_pred[i])] = ftrs_conf_mx[2, (0 - err_ftrs_pred[i])] + 1\n",
    "    elif (i < 160):\n",
    "        ftrs_conf_mx[3, (0 - err_ftrs_pred[i])] = ftrs_conf_mx[3, (0 - err_ftrs_pred[i])] + 1\n",
    "    elif (i < 200):\n",
    "        ftrs_conf_mx[4, (0 - err_ftrs_pred[i])] = ftrs_conf_mx[4, (0 - err_ftrs_pred[i])] + 1\n",
    "    elif (i < 240):\n",
    "        ftrs_conf_mx[5, (0 - err_ftrs_pred[i])] = ftrs_conf_mx[5, (0 - err_ftrs_pred[i])] + 1\n",
    "    elif (i < 280):\n",
    "        ftrs_conf_mx[6, (0 - err_ftrs_pred[i])] = ftrs_conf_mx[6, (0 - err_ftrs_pred[i])] + 1\n",
    "    else:\n",
    "        ftrs_conf_mx[7, (0 - err_ftrs_pred[i])] = ftrs_conf_mx[7, (0 - err_ftrs_pred[i])] + 1\n",
    "ftrs_conf_mx[0,0] = 40 - sum(ftrs_conf_mx[0,:])\n",
    "ftrs_conf_mx[1,1] = 40 - sum(ftrs_conf_mx[1,:])\n",
    "ftrs_conf_mx[2,2] = 40 - sum(ftrs_conf_mx[2,:])\n",
    "ftrs_conf_mx[3,3] = 40 - sum(ftrs_conf_mx[3,:])\n",
    "ftrs_conf_mx[4,4] = 40 - sum(ftrs_conf_mx[4,:])\n",
    "ftrs_conf_mx[5,5] = 40 - sum(ftrs_conf_mx[5,:])\n",
    "ftrs_conf_mx[6,6] = 40 - sum(ftrs_conf_mx[6,:])\n",
    "ftrs_conf_mx[7,7] = 40 - sum(ftrs_conf_mx[7,:])\n",
    "print(\"The confusion matrix was: \")\n",
    "print(ftrs_conf_mx)\n",
    "print(\"--------------------------------------------------\")\n",
    "print(\"Incorrectly classified images was: \")\n",
    "for i in ftrs_err_idx:\n",
    "    print(image_filename[i])\n",
    "print(\"##################################################\")\n",
    "print(\"################LBP classifier####################\")\n",
    "print(\"##################################################\")\n",
    "err_lbp_pred = test_y - test_y_lbp_pred\n",
    "err_lbp_pred_abs = abs(err_lbp_pred)\n",
    "lbp_cls_rate = sum(np.logical_not(err_lbp_pred_abs)) * 1.0 / test_y.shape[0]\n",
    "print(\"The classification rate was: %.12f\" % lbp_cls_rate)\n",
    "print(\"--------------------------------------------------\")\n",
    "lbp_conf_mx = np.zeros((8,8),dtype=int)\n",
    "lbp_err_idx = np.where(err_lbp_pred)\n",
    "lbp_err_idx = lbp_err_idx[0]\n",
    "for i in lbp_err_idx:\n",
    "    if (i < 40):\n",
    "        lbp_conf_mx[0, (0 - err_lbp_pred[i])] = lbp_conf_mx[0, (0 - err_lbp_pred[i])] + 1\n",
    "    elif (i < 80):\n",
    "        lbp_conf_mx[1, (0 - err_lbp_pred[i])] = lbp_conf_mx[1, (0 - err_lbp_pred[i])] + 1\n",
    "    elif (i < 120):\n",
    "        lbp_conf_mx[2, (0 - err_lbp_pred[i])] = lbp_conf_mx[2, (0 - err_lbp_pred[i])] + 1\n",
    "    elif (i < 160):\n",
    "        lbp_conf_mx[3, (0 - err_lbp_pred[i])] = lbp_conf_mx[3, (0 - err_lbp_pred[i])] + 1\n",
    "    elif (i < 200):\n",
    "        lbp_conf_mx[4, (0 - err_lbp_pred[i])] = lbp_conf_mx[4, (0 - err_lbp_pred[i])] + 1\n",
    "    elif (i < 240):\n",
    "        lbp_conf_mx[5, (0 - err_lbp_pred[i])] = lbp_conf_mx[5, (0 - err_lbp_pred[i])] + 1\n",
    "    elif (i < 280):\n",
    "        lbp_conf_mx[6, (0 - err_lbp_pred[i])] = lbp_conf_mx[6, (0 - err_lbp_pred[i])] + 1\n",
    "    else:\n",
    "        lbp_conf_mx[7, (0 - err_lbp_pred[i])] = lbp_conf_mx[7, (0 - err_lbp_pred[i])] + 1\n",
    "lbp_conf_mx[0,0] = 40 - sum(lbp_conf_mx[0,:])\n",
    "lbp_conf_mx[1,1] = 40 - sum(lbp_conf_mx[1,:])\n",
    "lbp_conf_mx[2,2] = 40 - sum(lbp_conf_mx[2,:])\n",
    "lbp_conf_mx[3,3] = 40 - sum(lbp_conf_mx[3,:])\n",
    "lbp_conf_mx[4,4] = 40 - sum(lbp_conf_mx[4,:])\n",
    "lbp_conf_mx[5,5] = 40 - sum(lbp_conf_mx[5,:])\n",
    "lbp_conf_mx[6,6] = 40 - sum(lbp_conf_mx[6,:])\n",
    "lbp_conf_mx[7,7] = 40 - sum(lbp_conf_mx[7,:])\n",
    "print(\"The confusion matrix was: \")\n",
    "print(lbp_conf_mx)\n",
    "print(\"--------------------------------------------------\")\n",
    "print(\"Incorrectly classified images was: \")\n",
    "for i in lbp_err_idx:\n",
    "    print(image_filename[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: Reflections\n",
    "\n",
    "Answer the following questions right here in this block:\n",
    "\n",
    "- Discuss the performance difference of the two different texture features.  Hypothesize reasons for observed differenes.\n",
    "\t\n",
    "\t_Your answer:_ At first, I set distance = \\[1, 2\\] in GLCM classifiers. And the classification rate of this GLCM classifier is 69\\%. Then I enlarge the distance list into \\[1, 2, 3, 4\\], then the classification rate is over 80\\%. However, the classification rate increase slowly when I try to enlarge distance list and angle list after that. And the LBP classifier just works excellent at first time. It have a classification rate over 95\\%. GLCM classifiers only use the general information of images, while LBP classifers record all rotationally invariant patterns. So LBP classifers have a much better performance than GLCM classifiers. As I inrease the distance list, GLCM classifiers can utilize more information about images, so their classification rates increase. \n",
    "    \n",
    "\n",
    "- For each of your two classifiers, discuss the misclassified images.  Were there any classes that were particularly difficult to distinguish?  Do the misclassified images (over all classes) have anything in common that would cause them to be misclassified?  If so what do they ahve in common, and why do you think it is confusing the classifier?\n",
    "\n",
    "\t_Your answer:_ In GLCM classifiers, class 1 and class 3 are particularly difficult to distinguish. And I think that the misclassified images of these two classes all have different shape and size bright block in their images. And if a kind of particular shape and size bright block is dominant of a image, the GLCM classifier may classify this image into wrong class. In LBP classifier there are not any classes that are particularly difficult to distinguish. And I don't think that misclassified images have anything in common that would cause them be misclassified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
